{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4bf34f-8e3a-4975-8f5b-14f6c5adb905",
   "metadata": {},
   "source": [
    "# This notebook will walk you through the steps carried out in \"method D\" of Mingyar et al. 2025\n",
    "\n",
    "First we input the necessary packages. \"is_tpt_ref\" is not necessary and is not actually used in this implimentation, but was trialed inported to try it out. I found it drastically slowed down our pipeline, and generally the juice wasn't worth the squeeze. If you want to try it out, it's on my github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46fd810e-8edc-4eab-9ee6-b89206f0e57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f52r714/.conda/envs/lang_4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from transformers import AutoModel\n",
    "from time import perf_counter as timer\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "import textwrap\n",
    "#from is_ref import ReferenceClassifier\n",
    "\n",
    "\n",
    "##This runs everything using the GPU (CUDA) if available. If not, use CPU. CPU is quite slow for large datasets. \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "#Load in the dataframe with the text already parsed into PDFs (see embedding notebook for details of how to do this)\n",
    "full_text_and_embeddings = pd.read_pickle(\"ajp_perc_prper_tpt_full_text_embeddings_2.pkl\")\n",
    "full_text_and_embeddings=full_text_and_embeddings.rename(columns={\"Full Text Embedding\":\"embedding\"})\n",
    "\n",
    "# Load embeddings onto GPU\n",
    "embeddings = torch.tensor(np.array(full_text_and_embeddings[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "\n",
    "# Using Jina:\n",
    "embedding_model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True, device_map=device)\n",
    "\n",
    "df=full_text_and_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52680a-921d-42b9-9a8f-237c860a08f6",
   "metadata": {},
   "source": [
    "Now we are going to load in the researcher-coded dataset. These changes are because the researchers were not consistent on how the journals were coded (i.e. \"Teacher\" vs \"teacher\"), and this just normalizes it. \n",
    "\n",
    "The asterisks were a symbol left over from coding, but are not needed in this analysis. This removes tags from the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b457b7f8-30c6-4114-88f4-c14fc38f7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv=pd.read_excel(\"paper_labels_M_S_2.xlsx\")\n",
    "\n",
    "csv['Category (M)']=csv['Category (M)'].str.replace(\"*\", \"\").replace(\"Journal business\", \"journal business\").replace(\"Teacher\", \"teacher\").replace('teaching', 'teacher').replace('Content', 'content').replace('content  ', 'content').replace('Student', 'student').replace(\"Content    \", \"content\").replace(\"Content  \", \"content\").replace(\"Teacher  \", \"teacher\").replace(\"Teacher \", \"teacher\").replace(\"Teaching\", \"teacher\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448dfc6d-b684-433f-a865-f2a885cd73d8",
   "metadata": {},
   "source": [
    "98 Papers are loaded from the spreadsheet, but let's double check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb473fd-e4fb-46ef-b55d-76b22e2fb1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9d746-5a81-4376-97c8-9536b7f3bf3f",
   "metadata": {},
   "source": [
    "It's good to check and make sure there are no accidents in the spreadsheet, such as a DOI that got put in the wrong place and is therefore doubled. Let's check for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2664b8-2363-479a-999e-285a5da3c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_doubles(csv):\n",
    "    for doi in csv['Doi']:\n",
    "        length=len(csv[csv['Doi']==doi]['Doi'])\n",
    "        if length>1:\n",
    "            print(doi)\n",
    "#check_doubles(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa088e8-d36a-4427-b198-440fc63acb16",
   "metadata": {},
   "source": [
    "Now that we're sure our human-labeled data look good, let's move on to defining our themes we're going to search over. \n",
    "\n",
    "the \"t1...t4\" labels are for readability and consistency. When implimented for deductive analysis, those wouldn't exist. But because we're cross referencing with human labeled data, this is necessary. \n",
    "\n",
    "The \"s1...s4\" labels are the actual \"search queries\" that you are entering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "279897e9-ad69-460b-bb39-60de9634e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t1 = \"Teaching students.\"\n",
    "t2 = \"Student focus.\"\n",
    "t3 = \"Physics content.\"\n",
    "t4= \"Journal business.\"\n",
    "\n",
    "query_list = [t1, t2, t3, t4]\n",
    "\n",
    "# Encode all query strings\n",
    "s1=\"Teaching. Laboratory equipment. Teaching methods.\" #Teacher\n",
    "s2=\"Student belonging. Student focused. Student agency.\" #Student\n",
    "s3=\"Physics content. Physics material. Math. Derivations.\" #Physics content\n",
    "s4=\"Editorials, book reviews, announcements, obituaries. Journal business. Reports on business. \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81707c67-c1eb-4462-a283-1eb2bd5bf9d3",
   "metadata": {},
   "source": [
    "Now that the search queries are defined, we need to convert the searches into embeddings. This needs to be done every time the queries are modified, so it cannot be done one and preserved unless the same queries are used every time. \n",
    "\n",
    "There are a number of embeddings models to choose from, some of which are free, some not. Generally speaking, the longer the vectors used for the model the greater context it can learn and the better your results will be. It's also important to be aware of the maximum number of tokens that your model can take, given that we are embedding entire papers. \n",
    "\n",
    "This model *must* be the same model used for embedding the text of the paper. You *cannot* mix and match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d344c1-2cfd-4472-8d43-9c7ae6f7194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['Teaching students.', 'Student focus.', 'Physics content.', 'Journal business.']\n",
      "Time take to get scores on 43607 embeddings: 0.01640 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "query_list_verbose=[s1, s2, s3, s4]\n",
    "query_embedding = embedding_model.encode(query_list_verbose, convert_to_tensor=True)\n",
    "\n",
    "print(f\"Query: {query_list}\")\n",
    "\n",
    "# Compute dot product similarity\n",
    "start_time = timer()\n",
    "dot_scores_1 = util.dot_score(a=query_embedding, b=embeddings).T  # Shape: (n_embeddings, 3)\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# Add columns for s1, s2, s3, s4 similarity to dataframe\n",
    "for n, t in enumerate(query_list):\n",
    "    df[t]= dot_scores_1[:, n].cpu().numpy()\n",
    "\n",
    "\n",
    "# Load classifier -- not currently used. This slows down batch processing time by a lot, so is recommended for smaller datasets. \n",
    "#model_path = \"trained_model.safetensors\"\n",
    "#classifier = ReferenceClassifier(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af9789-1028-49d2-b4f2-4183088d04b8",
   "metadata": {},
   "source": [
    "We calculate the topic score for each paper. For details, see Odden et al. 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e0dda7-29a0-4d9c-a81b-96eb0b385d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Default value of 'a' -- can adjust this from 0-90\n",
    "a = -10\n",
    "\n",
    "# Precompute the exponentials for efficiency\n",
    "exp_values = np.exp(a * (1-df[query_list]))\n",
    "\n",
    "# Compute the denominator for softmax-like normalization\n",
    "denominator = exp_values.sum(axis=1)\n",
    "\n",
    "# Create new score columns\n",
    "\n",
    "for col in query_list:\n",
    "    score_col = f\"{col.strip()}_score\"\n",
    "    df[score_col] = exp_values[col] / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8eadd-3e6e-44cb-9bcf-017621f09090",
   "metadata": {},
   "source": [
    "We currently have two dataframes moving around, one from the human labeled dataset and one from the papers' embeddings. We need to merge the two together on their idenfifying column (doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2c65f2-33dd-4b7f-9d7a-cedd696fc487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabs labels form the CSV and inserts them into the dataframe. Renames the dataframe df_labels\n",
    "\n",
    "weighted_score_ql=[]\n",
    "for query in query_list:\n",
    "    weighted_score_ql.append(f\"{query}_score_weighted\")\n",
    "\n",
    "\n",
    "csv=csv.rename(columns={\"Doi\": \"doi\"})\n",
    "csv['doi']=csv['doi'].str.replace(\" \", \"\")\n",
    "csv['doi']=csv['doi'].str.replace(\"\\'\", \"\")\n",
    "csv['doi']=csv['doi'].str.replace(\"https://doi.org/\", \"\")\n",
    "\n",
    "df_full_text=pd.merge(df, csv[['Category (M)', 'doi']], on='doi', how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750ec87-c9ed-4049-b8ba-a121171cd81e",
   "metadata": {},
   "source": [
    "Let's check to see if everything merged as expected. \n",
    "\n",
    "Here we're making sure that none of the hand-labeled items were missed or dropped by cross checking it with the larger dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c29c32-bfd3-415a-a36b-7b7518d8a7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 rows unique to 'csv' dataframe\n",
      "Found 43509 rows unique to 'df_labels' dataframe\n",
      "\n",
      "Rows unique to 'csv' dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Category (M)</th>\n",
       "      <th>doi</th>\n",
       "      <th>Category (S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title , Abstract, Journal, Category (M), doi, Category (S)]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows unique to 'df_labels' dataframe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>doi</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>char_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>sentence_chunks</th>\n",
       "      <th>num_chunks</th>\n",
       "      <th>embedding</th>\n",
       "      <th>Teaching students.</th>\n",
       "      <th>Student focus.</th>\n",
       "      <th>Physics content.</th>\n",
       "      <th>Journal business.</th>\n",
       "      <th>Teaching students._score</th>\n",
       "      <th>Student focus._score</th>\n",
       "      <th>Physics content._score</th>\n",
       "      <th>Journal business._score</th>\n",
       "      <th>Category (M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Make a Mystery Circuit with a Bar Light Fixtur...</td>\n",
       "      <td>10.1119/1.2715425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>7234</td>\n",
       "      <td>1808.50</td>\n",
       "      <td>[Make a Mystery Circuit with a Bar Light Fixtu...</td>\n",
       "      <td>81</td>\n",
       "      <td>[[Make a Mystery Circuit with a Bar Light Fixt...</td>\n",
       "      <td>17</td>\n",
       "      <td>[tensor(-0.0012), tensor(0.0354), tensor(0.108...</td>\n",
       "      <td>0.525292</td>\n",
       "      <td>0.338646</td>\n",
       "      <td>0.458282</td>\n",
       "      <td>0.336486</td>\n",
       "      <td>0.550147</td>\n",
       "      <td>0.085091</td>\n",
       "      <td>0.281489</td>\n",
       "      <td>0.083273</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton K...</td>\n",
       "      <td>10.1119/1.2343976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>4633</td>\n",
       "      <td>1158.25</td>\n",
       "      <td>[AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton ...</td>\n",
       "      <td>58</td>\n",
       "      <td>[[AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton...</td>\n",
       "      <td>12</td>\n",
       "      <td>[tensor(0.0039), tensor(-0.0006), tensor(0.114...</td>\n",
       "      <td>0.547897</td>\n",
       "      <td>0.314111</td>\n",
       "      <td>0.479536</td>\n",
       "      <td>0.343349</td>\n",
       "      <td>0.577820</td>\n",
       "      <td>0.055779</td>\n",
       "      <td>0.291679</td>\n",
       "      <td>0.074722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modeling Electricity: Model-Based Inquiry with...</td>\n",
       "      <td>10.1119/1.4745686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>17496</td>\n",
       "      <td>4374.00</td>\n",
       "      <td>[Modeling Electricity: Model-Based Inquiry wit...</td>\n",
       "      <td>140</td>\n",
       "      <td>[[Modeling Electricity: Model-Based Inquiry wi...</td>\n",
       "      <td>28</td>\n",
       "      <td>[tensor(0.0564), tensor(-0.0816), tensor(0.150...</td>\n",
       "      <td>0.533192</td>\n",
       "      <td>0.390003</td>\n",
       "      <td>0.500644</td>\n",
       "      <td>0.263966</td>\n",
       "      <td>0.492910</td>\n",
       "      <td>0.117736</td>\n",
       "      <td>0.355970</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two Approaches to Learning Physics \\r\\n\"I look...</td>\n",
       "      <td>10.1119/1.2342910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>37322</td>\n",
       "      <td>9330.50</td>\n",
       "      <td>[Two Approaches to Learning Physics \\r\\n\"I loo...</td>\n",
       "      <td>324</td>\n",
       "      <td>[[Two Approaches to Learning Physics \\r\\n\"I lo...</td>\n",
       "      <td>65</td>\n",
       "      <td>[tensor(0.0499), tensor(-0.1132), tensor(0.178...</td>\n",
       "      <td>0.538308</td>\n",
       "      <td>0.392010</td>\n",
       "      <td>0.579177</td>\n",
       "      <td>0.325154</td>\n",
       "      <td>0.350258</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.527082</td>\n",
       "      <td>0.041559</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\r\\nJochen Kuhn and Patrik Vogt, Column Editor...</td>\n",
       "      <td>10.1119/1.4865529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>6621</td>\n",
       "      <td>1655.25</td>\n",
       "      <td>[\\r\\nJochen Kuhn and Patrik Vogt, Column Edito...</td>\n",
       "      <td>76</td>\n",
       "      <td>[[\\r\\nJochen Kuhn and Patrik Vogt, Column Edit...</td>\n",
       "      <td>16</td>\n",
       "      <td>[tensor(0.0292), tensor(-0.0519), tensor(0.055...</td>\n",
       "      <td>0.378926</td>\n",
       "      <td>0.262477</td>\n",
       "      <td>0.467860</td>\n",
       "      <td>0.276191</td>\n",
       "      <td>0.243691</td>\n",
       "      <td>0.076051</td>\n",
       "      <td>0.593028</td>\n",
       "      <td>0.087230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43602</th>\n",
       "      <td>Examining faculty choices while implementing t...</td>\n",
       "      <td>10.1119/perc.2023.pr.Willison</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>24881</td>\n",
       "      <td>6220.25</td>\n",
       "      <td>[Examining faculty choices while implementing ...</td>\n",
       "      <td>203</td>\n",
       "      <td>[[Examining faculty choices while implementing...</td>\n",
       "      <td>41</td>\n",
       "      <td>[tensor(0.1635), tensor(-0.1263), tensor(0.057...</td>\n",
       "      <td>0.378620</td>\n",
       "      <td>0.383887</td>\n",
       "      <td>0.397787</td>\n",
       "      <td>0.285023</td>\n",
       "      <td>0.273406</td>\n",
       "      <td>0.288194</td>\n",
       "      <td>0.331168</td>\n",
       "      <td>0.107231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43603</th>\n",
       "      <td>Analyzing the dimensionality of the Energy and...</td>\n",
       "      <td>10.1119/perc.2023.pr.Wu</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>24460</td>\n",
       "      <td>6115.00</td>\n",
       "      <td>[Analyzing the dimensionality of the Energy an...</td>\n",
       "      <td>227</td>\n",
       "      <td>[[Analyzing the dimensionality of the Energy a...</td>\n",
       "      <td>46</td>\n",
       "      <td>[tensor(0.0763), tensor(-0.1726), tensor(0.054...</td>\n",
       "      <td>0.371197</td>\n",
       "      <td>0.347483</td>\n",
       "      <td>0.457647</td>\n",
       "      <td>0.243488</td>\n",
       "      <td>0.225147</td>\n",
       "      <td>0.177614</td>\n",
       "      <td>0.534458</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43604</th>\n",
       "      <td>Students’ use of symmetry as a tool for sensem...</td>\n",
       "      <td>10.1119/perc.2023.pr.Young</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>27598</td>\n",
       "      <td>6899.50</td>\n",
       "      <td>[Students’ use of symmetry as a tool for sense...</td>\n",
       "      <td>264</td>\n",
       "      <td>[[Students’ use of symmetry as a tool for sens...</td>\n",
       "      <td>53</td>\n",
       "      <td>[tensor(0.1260), tensor(-0.0853), tensor(0.105...</td>\n",
       "      <td>0.415883</td>\n",
       "      <td>0.419996</td>\n",
       "      <td>0.427131</td>\n",
       "      <td>0.264395</td>\n",
       "      <td>0.295781</td>\n",
       "      <td>0.308200</td>\n",
       "      <td>0.330995</td>\n",
       "      <td>0.065023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43605</th>\n",
       "      <td>Analyzing Physics Majors’ Specialization Low I...</td>\n",
       "      <td>10.1119/perc.2023.pr.Zohrabi_Alaee</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>27954</td>\n",
       "      <td>6988.50</td>\n",
       "      <td>[Analyzing Physics Majors’ Specialization Low ...</td>\n",
       "      <td>222</td>\n",
       "      <td>[[Analyzing Physics Majors’ Specialization Low...</td>\n",
       "      <td>45</td>\n",
       "      <td>[tensor(0.0705), tensor(-0.1829), tensor(0.015...</td>\n",
       "      <td>0.390673</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.496636</td>\n",
       "      <td>0.326901</td>\n",
       "      <td>0.134306</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.387513</td>\n",
       "      <td>0.070980</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43606</th>\n",
       "      <td>Analyzing AI and student responses through the...</td>\n",
       "      <td>10.1119/perc.2023.pr.Zollman</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>27691</td>\n",
       "      <td>6922.75</td>\n",
       "      <td>[Analyzing AI and student responses through th...</td>\n",
       "      <td>219</td>\n",
       "      <td>[[Analyzing AI and student responses through t...</td>\n",
       "      <td>44</td>\n",
       "      <td>[tensor(0.1471), tensor(-0.1589), tensor(0.174...</td>\n",
       "      <td>0.350984</td>\n",
       "      <td>0.364413</td>\n",
       "      <td>0.413796</td>\n",
       "      <td>0.211134</td>\n",
       "      <td>0.234478</td>\n",
       "      <td>0.268180</td>\n",
       "      <td>0.439434</td>\n",
       "      <td>0.057908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43509 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  \\\n",
       "0      Make a Mystery Circuit with a Bar Light Fixtur...   \n",
       "1      AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton K...   \n",
       "2      Modeling Electricity: Model-Based Inquiry with...   \n",
       "3      Two Approaches to Learning Physics \\r\\n\"I look...   \n",
       "4      \\r\\nJochen Kuhn and Patrik Vogt, Column Editor...   \n",
       "...                                                  ...   \n",
       "43602  Examining faculty choices while implementing t...   \n",
       "43603  Analyzing the dimensionality of the Energy and...   \n",
       "43604  Students’ use of symmetry as a tool for sensem...   \n",
       "43605  Analyzing Physics Majors’ Specialization Low I...   \n",
       "43606  Analyzing AI and student responses through the...   \n",
       "\n",
       "                                      doi    year journal  char_count  \\\n",
       "0                       10.1119/1.2715425     NaN     tpt        7234   \n",
       "1                       10.1119/1.2343976     NaN     tpt        4633   \n",
       "2                       10.1119/1.4745686     NaN     tpt       17496   \n",
       "3                       10.1119/1.2342910     NaN     tpt       37322   \n",
       "4                       10.1119/1.4865529     NaN     tpt        6621   \n",
       "...                                   ...     ...     ...         ...   \n",
       "43602       10.1119/perc.2023.pr.Willison  2023.0    perc       24881   \n",
       "43603             10.1119/perc.2023.pr.Wu  2023.0    perc       24460   \n",
       "43604          10.1119/perc.2023.pr.Young  2023.0    perc       27598   \n",
       "43605  10.1119/perc.2023.pr.Zohrabi_Alaee  2023.0    perc       27954   \n",
       "43606        10.1119/perc.2023.pr.Zollman  2023.0    perc       27691   \n",
       "\n",
       "       token_count                                          sentences  \\\n",
       "0          1808.50  [Make a Mystery Circuit with a Bar Light Fixtu...   \n",
       "1          1158.25  [AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton ...   \n",
       "2          4374.00  [Modeling Electricity: Model-Based Inquiry wit...   \n",
       "3          9330.50  [Two Approaches to Learning Physics \\r\\n\"I loo...   \n",
       "4          1655.25  [\\r\\nJochen Kuhn and Patrik Vogt, Column Edito...   \n",
       "...            ...                                                ...   \n",
       "43602      6220.25  [Examining faculty choices while implementing ...   \n",
       "43603      6115.00  [Analyzing the dimensionality of the Energy an...   \n",
       "43604      6899.50  [Students’ use of symmetry as a tool for sense...   \n",
       "43605      6988.50  [Analyzing Physics Majors’ Specialization Low ...   \n",
       "43606      6922.75  [Analyzing AI and student responses through th...   \n",
       "\n",
       "       sentences_count                                    sentence_chunks  \\\n",
       "0                   81  [[Make a Mystery Circuit with a Bar Light Fixt...   \n",
       "1                   58  [[AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton...   \n",
       "2                  140  [[Modeling Electricity: Model-Based Inquiry wi...   \n",
       "3                  324  [[Two Approaches to Learning Physics \\r\\n\"I lo...   \n",
       "4                   76  [[\\r\\nJochen Kuhn and Patrik Vogt, Column Edit...   \n",
       "...                ...                                                ...   \n",
       "43602              203  [[Examining faculty choices while implementing...   \n",
       "43603              227  [[Analyzing the dimensionality of the Energy a...   \n",
       "43604              264  [[Students’ use of symmetry as a tool for sens...   \n",
       "43605              222  [[Analyzing Physics Majors’ Specialization Low...   \n",
       "43606              219  [[Analyzing AI and student responses through t...   \n",
       "\n",
       "       num_chunks                                          embedding  \\\n",
       "0              17  [tensor(-0.0012), tensor(0.0354), tensor(0.108...   \n",
       "1              12  [tensor(0.0039), tensor(-0.0006), tensor(0.114...   \n",
       "2              28  [tensor(0.0564), tensor(-0.0816), tensor(0.150...   \n",
       "3              65  [tensor(0.0499), tensor(-0.1132), tensor(0.178...   \n",
       "4              16  [tensor(0.0292), tensor(-0.0519), tensor(0.055...   \n",
       "...           ...                                                ...   \n",
       "43602          41  [tensor(0.1635), tensor(-0.1263), tensor(0.057...   \n",
       "43603          46  [tensor(0.0763), tensor(-0.1726), tensor(0.054...   \n",
       "43604          53  [tensor(0.1260), tensor(-0.0853), tensor(0.105...   \n",
       "43605          45  [tensor(0.0705), tensor(-0.1829), tensor(0.015...   \n",
       "43606          44  [tensor(0.1471), tensor(-0.1589), tensor(0.174...   \n",
       "\n",
       "       Teaching students.  Student focus.  Physics content.  \\\n",
       "0                0.525292        0.338646          0.458282   \n",
       "1                0.547897        0.314111          0.479536   \n",
       "2                0.533192        0.390003          0.500644   \n",
       "3                0.538308        0.392010          0.579177   \n",
       "4                0.378926        0.262477          0.467860   \n",
       "...                   ...             ...               ...   \n",
       "43602            0.378620        0.383887          0.397787   \n",
       "43603            0.371197        0.347483          0.457647   \n",
       "43604            0.415883        0.419996          0.427131   \n",
       "43605            0.390673        0.501591          0.496636   \n",
       "43606            0.350984        0.364413          0.413796   \n",
       "\n",
       "       Journal business.  Teaching students._score  Student focus._score  \\\n",
       "0               0.336486                  0.550147              0.085091   \n",
       "1               0.343349                  0.577820              0.055779   \n",
       "2               0.263966                  0.492910              0.117736   \n",
       "3               0.325154                  0.350258              0.081101   \n",
       "4               0.276191                  0.243691              0.076051   \n",
       "...                  ...                       ...                   ...   \n",
       "43602           0.285023                  0.273406              0.288194   \n",
       "43603           0.243488                  0.225147              0.177614   \n",
       "43604           0.264395                  0.295781              0.308200   \n",
       "43605           0.326901                  0.134306              0.407200   \n",
       "43606           0.211134                  0.234478              0.268180   \n",
       "\n",
       "       Physics content._score  Journal business._score Category (M)  \n",
       "0                    0.281489                 0.083273          NaN  \n",
       "1                    0.291679                 0.074722          NaN  \n",
       "2                    0.355970                 0.033384          NaN  \n",
       "3                    0.527082                 0.041559          NaN  \n",
       "4                    0.593028                 0.087230          NaN  \n",
       "...                       ...                      ...          ...  \n",
       "43602                0.331168                 0.107231          NaN  \n",
       "43603                0.534458                 0.062781          NaN  \n",
       "43604                0.330995                 0.065023          NaN  \n",
       "43605                0.387513                 0.070980          NaN  \n",
       "43606                0.439434                 0.057908          NaN  \n",
       "\n",
       "[43509 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "csv_dois = set(csv['doi'].dropna())\n",
    "labels_dois = set(df_full_text['doi'].dropna())\n",
    "\n",
    "# Find DOIs unique to each dataframe\n",
    "dois_only_in_csv = csv_dois - labels_dois\n",
    "dois_only_in_labels = labels_dois - csv_dois\n",
    "\n",
    "# Filter rows based on unique DOIs\n",
    "csv_unique_rows = csv[csv['doi'].isin(dois_only_in_csv)]\n",
    "labels_unique_rows = df_full_text[df_full_text['doi'].isin(dois_only_in_labels)]\n",
    "\n",
    "# Display results\n",
    "print(f\"Found {len(csv_unique_rows)} rows unique to 'csv' dataframe\")\n",
    "print(f\"Found {len(labels_unique_rows)} rows unique to 'df_labels' dataframe\")\n",
    "\n",
    "print(\"\\nRows unique to 'csv' dataframe:\")\n",
    "display(csv_unique_rows)\n",
    "\n",
    "print(\"\\nRows unique to 'df_labels' dataframe:\")\n",
    "display(labels_unique_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a307e-eb8b-4f53-ad70-3358ed57ec91",
   "metadata": {},
   "source": [
    "There are zero unique rows in the csv, as expected. At this point, the dataframe has researcher defined labels \n",
    "\n",
    "Now we need to define the function that calculates the refined centroids. \n",
    "\n",
    "For more detail about the technique, see the associated paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efe9ceed-5abd-463e-ae32-1a1606c5b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.ndimage as nd\n",
    "import numpy as np\n",
    "\n",
    "  \n",
    "\n",
    "def centroid_labeling_whole_text(df, K=1, whole_text=True):\n",
    "    \"\"\"\n",
    "    Perform advanced centroid-based topic labeling using full-text embeddings.\n",
    "    \n",
    "    This function implements an enhanced centroid-based classification approach that:\n",
    "    1. Identifies archetypal papers for each topic category based on raw scores\n",
    "    2. Creates topic centroids from full-text embeddings of archetypal papers\n",
    "    3. Computes cosine similarity between all papers and topic centroids\n",
    "    4. Applies Topic Score to generate topic probabilities\n",
    "    5. Assigns the most likely topic label to each paper\n",
    "    \n",
    "    This approach differs from sentence-based methods by using document-level \n",
    "    embeddings, potentially capturing broader semantic themes and overall document structure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing papers to be labeled. Must include:\n",
    "        - 'doi': Document identifiers for each paper\n",
    "        - '{label}_score' columns for each label in query_list (raw scores)\n",
    "        - 'Full Text Embedding' column (when whole_text=True)\n",
    "    K : int, optional\n",
    "        Number of top-scoring archetypal papers to use per topic category for \n",
    "        centroid creation. Automatically adjusted if fewer papers are available\n",
    "        (default: 1)\n",
    "    whole_text : bool, optional\n",
    "        Whether to use full-text embeddings. Currently only True is supported\n",
    "        (default: True)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Input dataframe enhanced with additional columns:\n",
    "        - '{label}_Advanced Centroid dotp': Cosine similarity scores to each topic centroid\n",
    "        - '{label}_Advanced Centroid TS': Topic probabilities\n",
    "        - 'Main Group Advanced Centroid': Predicted topic label (highest scoring category)\n",
    "        \n",
    "    Global Dependencies\n",
    "    -------------------\n",
    "    Requires the following global variables to be defined:\n",
    "    - query_list : list\n",
    "        List of topic labels/categories to classify papers into\n",
    "    - df_full_text : pandas.DataFrame\n",
    "        Dataframe containing full-text embeddings with 'Full Text Embedding' column\n",
    "    - a : float\n",
    "        Temperature scaling factor for topic score (controls topic-mixedness)\n",
    "    - nd : module\n",
    "        Numerical computation module with rotate function (scipy.ndimage)\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Uses raw scores ('{label}_score') rather than weighted scores for archetypal selection\n",
    "    - Automatically handles cases where K exceeds the number of available papers\n",
    "    - Cosine similarity is used instead of dot products for better normalized comparison\n",
    "    - The topic score transformation includes array rotation operations for proper alignment\n",
    "    - Currently only supports whole_text=True mode; sentence-level fallback not implemented\n",
    "    \n",
    "    Algorithm Steps\n",
    "    ---------------\n",
    "    1. **Archetypal Selection**: Select top K papers per category based on raw scores\n",
    "    2. **Centroid Creation**: Average full-text embeddings of archetypal papers \n",
    "       to create topic centroids\n",
    "    3. **Similarity Calculation**: Compute cosine similarity between all paper \n",
    "       embeddings and topic centroids\n",
    "    4. **Topic Scoring**: Topic score to convert similarities \n",
    "       to probabilities with array transformations\n",
    "    5. **Label Assignment**: Assign topic with highest probability as main group\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If whole_text=False (not currently supported)\n",
    "    IndexError\n",
    "        If required columns are missing from input dataframes\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Assuming global variables are properly set up\n",
    "    >>> labeled_df = advanced_centroid_labeling(papers_df, K=3, whole_text=True)\n",
    "    >>> print(labeled_df['Main Group Advanced Centroid'].value_counts())\n",
    "    >>> # Check similarity scores\n",
    "    >>> similarity_cols = [col for col in labeled_df.columns if 'dotp' in col]\n",
    "    >>> print(labeled_df[similarity_cols].describe())\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    cosine_similarity : Used for measuring embedding similarity\n",
    "    numpy.mean : Used for averaging embeddings\n",
    "    centroid_labeling_sentences : Alternative sentence-level approach\n",
    "    \"\"\"\n",
    "    df_labels = df.copy()\n",
    "    print(f\"K: {K} whole_text: {whole_text}\")\n",
    "\n",
    "    # Step 1: Identify archetypal papers\n",
    "    archetypal_papers = {}\n",
    "    for label in query_list:\n",
    "        k_actual = min(K, len(df_labels))\n",
    "        top_k_dois = df_labels.sort_values(by=f\"{label}_score\", ascending=False).head(k_actual)['doi'].tolist()\n",
    "        archetypal_papers[label] = top_k_dois\n",
    "    \n",
    "    # Step 2: Compute centroids\n",
    "    centroids = {}\n",
    "    for label, dois in archetypal_papers.items():\n",
    "        top_embeddings = []\n",
    "\n",
    "        for doi in dois:\n",
    "            if whole_text:\n",
    "                # Use full-text embedding directly\n",
    "                paper_embedding = df_labels[df_labels['doi'] == doi]['embedding'].values\n",
    "                if len(paper_embedding) > 0:\n",
    "                    top_embeddings.append(paper_embedding[0])\n",
    "                else:\n",
    "                    print(\"There appears to be no full-text embeddings\")\n",
    "            centroid = np.mean(np.stack(top_embeddings), axis=0)\n",
    "            centroids[label] = centroid\n",
    "\n",
    "    # Step 3: Average embeddings per paper\n",
    "    avg_embeddings = []\n",
    "\n",
    "    # Step 4: Cosine similarity to centroids\n",
    "    dot_prods={}\n",
    "    for label in query_list:\n",
    "        new_label=label+\"_Advanced Centroid dotp\"\n",
    "        sent_emb=[item for item in df_labels['embedding']]\n",
    "        topic_emb=[centroids[label]]*len(sent_emb) #Copies the topic centroid embedding to be equal in length to sent_emb. For the case of the whole paper, this should just multiply it by one\n",
    "        dot_prods[new_label]= np.diag(np.array(cosine_similarity(topic_emb, sent_emb)))  ##This uses cosine similarity instead of dot product. The vectors used here are normalized so that isn't a problem\n",
    "    for new_label in [label+\"_Advanced Centroid dotp\" for label in query_list]:\n",
    "        df_labels[new_label]=dot_prods[new_label]\n",
    "    # Step 5: Topic Scoring \n",
    "    topic_scores=[]\n",
    "    ac_dotp_labels=[label+\"_Advanced Centroid dotp\" for label in query_list]\n",
    "    for index, row in df_labels.iterrows():\n",
    "        exp_values =np.exp(a* (1-row[ac_dotp_labels].values.astype(float)))\n",
    "        denominator = exp_values.sum(axis=0)\n",
    "        topic_scores.append( exp_values / denominator )\n",
    "    topic_scores=np.flip(nd.rotate(np.array(topic_scores),90), axis=0)\n",
    "    ac_ts_labels=[label+\"_Advanced Centroid TS\" for label in query_list]\n",
    "    for n, label in enumerate(ac_ts_labels):\n",
    "        df_labels[label]=topic_scores[n]\n",
    "    \n",
    "    # Step 7: Identify main group\n",
    "    df_labels['Main Group Advanced Centroid'] = df_labels[[f\"{label}_Advanced Centroid TS\" for label in query_list]].idxmax(axis=1)\n",
    "    df_labels['Main Group Advanced Centroid'] = df_labels['Main Group Advanced Centroid'].str.replace(\"_Advanced Centroid TS\", \"\")\n",
    "    \n",
    "    \n",
    "    return df_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9297b-d694-4a6e-8705-6fa6cf4d3024",
   "metadata": {},
   "source": [
    "Now we need to define the function that evaluates the model on mutiple different metrics. This is where the hand-labeled data are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10804eb-2e99-497e-a7e5-c7126a52d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_labeling_recall(df, teacher_col, student_col, content_col, journal_col, main_group):\n",
    "    # Mapping of category labels to full column names\n",
    "    category_map = {\n",
    "        't': teacher_col.strip(),\n",
    "        's': student_col.strip(),\n",
    "        'c': content_col.strip(),\n",
    "        'jb': journal_col.strip()\n",
    "    }\n",
    "\n",
    "    def compare_labels(row):\n",
    "        category = row['Category (M)']\n",
    "        if pd.isna(category):\n",
    "            return np.nan\n",
    "        expected_group = category_map.get(category.strip().lower())\n",
    "        return expected_group == row[main_group]\n",
    "\n",
    "    df['Correctly labeled'] = df.apply(compare_labels, axis=1)\n",
    "    valid = df[~df['Category (M)'].isna()].copy()\n",
    "\n",
    "    print(\"Here:\")\n",
    "    print(len(valid))\n",
    "\n",
    "    total = len(valid)\n",
    "    correct = valid['Correctly labeled'].sum()\n",
    "    percent_correct = 100 * correct / total if total > 0 else 0\n",
    "\n",
    "    print(f\"1. Total number of entries with a value in 'Category (M)': {total}\")\n",
    "    print(f\"2. Percent correctly labeled (accuracy): {percent_correct:.2f}%\")\n",
    "\n",
    "    # Per-category accuracy (recall), precision, false positive rate\n",
    "    print(\"3. Detailed metrics per category:\")\n",
    "    for cat, expected_val in category_map.items():\n",
    "        # True Positives: predicted = expected = this category\n",
    "        tp = valid[(valid['Category (M)'].str.lower() == cat) & (valid[main_group] == expected_val)]\n",
    "        \n",
    "        # False Negatives: actual is this category, but predicted is not\n",
    "        fn = valid[(valid['Category (M)'].str.lower() == cat) & (valid[main_group] != expected_val)]\n",
    "\n",
    "        # False Positives: predicted is this category, but actual is not\n",
    "        fp = valid[(valid['Category (M)'].str.lower() != cat) & (valid[main_group] == expected_val)]\n",
    "\n",
    "        # True Negatives: actual and predicted are both *not* this category\n",
    "        tn = valid[(valid['Category (M)'].str.lower() != cat) & (valid[main_group] != expected_val)]\n",
    "\n",
    "        tp_count = len(tp)\n",
    "        fn_count = len(fn)\n",
    "        fp_count = len(fp)\n",
    "        tn_count = len(tn)\n",
    "\n",
    "        recall = tp_count / (tp_count + fn_count) if (tp_count + fn_count) > 0 else 0\n",
    "        precision = tp_count / (tp_count + fp_count) if (tp_count + fp_count) > 0 else 0\n",
    "        fpr = fp_count / (fp_count + tn_count) if (fp_count + tn_count) > 0 else 0\n",
    "        acc = (tp_count + tn_count) / (tp_count + tn_count + fp_count + fn_count)\n",
    "\n",
    "        print(f\"   {cat.title()}:\")\n",
    "        print(f\"      Recall (TP / TP + FN): {recall:.2f}\")\n",
    "        print(f\"      Precision (TP / TP + FP): {precision:.2f}\")\n",
    "        print(f\"      False Positive Rate (FP / FP + TN): {fpr:.2f}\")\n",
    "        print(f\"      Accuracy (TP + TN / All): {acc:.2f}\")\n",
    "\n",
    "    # Label distributions\n",
    "    print(\"4. Label distribution:\")\n",
    "    cat_counts = valid['Category (M)'].str.lower().value_counts(normalize=True)\n",
    "    main_counts = valid[main_group].value_counts(normalize=True)\n",
    "    \n",
    "    print(\"Category (M):\")\n",
    "    for k, v in cat_counts.items():\n",
    "        print(f\"     {k.title()}: {v:.2%}\")\n",
    "    print(\"Automated:\")\n",
    "    for k, v in main_counts.items():\n",
    "        print(f\"     {k[:40].strip()}: {v:.2%}\")\n",
    "\n",
    "    # Return doi and correctness\n",
    "    result = valid[['doi', 'Correctly labeled']].reset_index(drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58962fd4-fc0a-47e1-89a9-aade602c3b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 4 whole_text: True\n"
     ]
    }
   ],
   "source": [
    "df1=centroid_labeling_whole_text(df_full_text, K=4) #This processes the centroids and labels the papers by their most likely group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "082fd669-5250-4149-87e0-3089264c016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here:\n",
      "98\n",
      "1. Total number of entries with a value in 'Category (M)': 98\n",
      "2. Percent correctly labeled (accuracy): 60.20%\n",
      "3. Detailed metrics per category:\n",
      "   T:\n",
      "      Recall (TP / TP + FN): 0.78\n",
      "      Precision (TP / TP + FP): 0.44\n",
      "      False Positive Rate (FP / FP + TN): 0.31\n",
      "      Accuracy (TP + TN / All): 0.71\n",
      "   S:\n",
      "      Recall (TP / TP + FN): 0.88\n",
      "      Precision (TP / TP + FP): 0.88\n",
      "      False Positive Rate (FP / FP + TN): 0.02\n",
      "      Accuracy (TP + TN / All): 0.96\n",
      "   C:\n",
      "      Recall (TP / TP + FN): 0.64\n",
      "      Precision (TP / TP + FP): 0.66\n",
      "      False Positive Rate (FP / FP + TN): 0.17\n",
      "      Accuracy (TP + TN / All): 0.77\n",
      "   Jb:\n",
      "      Recall (TP / TP + FN): 0.23\n",
      "      Precision (TP / TP + FP): 0.67\n",
      "      False Positive Rate (FP / FP + TN): 0.04\n",
      "      Accuracy (TP + TN / All): 0.77\n",
      "4. Label distribution:\n",
      "Category (M):\n",
      "     C: 33.67%\n",
      "     Jb: 26.53%\n",
      "     T: 23.47%\n",
      "     S: 16.33%\n",
      "Automated:\n",
      "     Teaching students.: 41.84%\n",
      "     Physics content.: 32.65%\n",
      "     Student focus.: 16.33%\n",
      "     Journal business.: 9.18%\n"
     ]
    }
   ],
   "source": [
    "mg1=\"Main Group Advanced Centroid\" #Advanced centroids based on full text\n",
    "\n",
    "#mg=\"MG Score Full Embedding\"\n",
    "\n",
    "##This is Group D, the one that matters\n",
    "results = evaluate_labeling_recall(\n",
    "    df1,\n",
    "    query_list[0], #teacher_col\n",
    "    query_list[1], #student_col\n",
    "    query_list[2], #content_col\n",
    "    query_list[3], #journal_col\n",
    "    mg1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "711b064d-e2c4-4dea-8e99-83c065a277e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6853d506-83f6-42c1-98a2-7b7eaeb7400c",
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(df1, \"full_text_refined_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_4",
   "language": "python",
   "name": "lang_4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
