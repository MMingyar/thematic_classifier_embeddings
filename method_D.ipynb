{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fd810e-8edc-4eab-9ee6-b89206f0e57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f52r714/.conda/envs/lang_4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from transformers import AutoModel\n",
    "from time import perf_counter as timer\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "import textwrap\n",
    "from is_tpt_ref import ReferenceClassifier\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "full_text_and_embeddings = pd.read_pickle(\"ajp_perc_prper_tpt_full_text_embeddings_2.pkl\")\n",
    "full_text_and_embeddings=full_text_and_embeddings.rename(columns={\"Full Text Embedding\":\"embedding\"})\n",
    "\n",
    "# Load embeddings onto GPU\n",
    "embeddings = torch.tensor(np.array(full_text_and_embeddings[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "\n",
    "# Load model\n",
    "#embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", device=device)\n",
    "# OR if you are using Jina:\n",
    "embedding_model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True, device_map=device)\n",
    "\n",
    "df=full_text_and_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b457b7f8-30c6-4114-88f4-c14fc38f7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv=pd.read_excel(\"paper_labels_M_S_2.xlsx\")\n",
    "\n",
    "csv['Category (M)']=csv['Category (M)'].str.replace(\"*\", \"\").replace(\"Journal business\", \"journal business\").replace(\"Teacher\", \"teacher\").replace('teaching', 'teacher').replace('Content', 'content').replace('content  ', 'content').replace('Student', 'student').replace(\"Content    \", \"content\").replace(\"Content  \", \"content\").replace(\"Teacher  \", \"teacher\").replace(\"Teacher \", \"teacher\").replace(\"Teaching\", \"teacher\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb473fd-e4fb-46ef-b55d-76b22e2fb1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2664b8-2363-479a-999e-285a5da3c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_doubles(csv):\n",
    "    for doi in csv['Doi']:\n",
    "        length=len(csv[csv['Doi']==doi]['Doi'])\n",
    "        if length>1:\n",
    "            print(doi)\n",
    "#check_doubles(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c9504-4587-490c-83a5-ef0460d31f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279897e9-ad69-460b-bb39-60de9634e978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['Teaching students.', 'Student focus.', 'Physics content.', 'Journal business.']\n",
      "Time take to get scores on 43607 embeddings: 0.02978 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1 = \"Teaching students.\"\n",
    "t2 = \"Student focus.\"\n",
    "t3 = \"Physics content.\"\n",
    "t4= \"Journal business.\"\n",
    "\n",
    "query_list = [t1, t2, t3, t4]\n",
    "\n",
    "# Encode all query strings\n",
    "s1=\"string standing wave frequency waves line tension aerator vibration transverse.\" #Teacher\n",
    "s2=\"energy free representations ideas useful work different students conserved like.\" #Student\n",
    "s3=\"force hypothetical natural object place velocity objects rock mass constant.\" #Physics content\n",
    "#s4=\"Editorials, book reviews, announcements, obituaries. Journal business. Reports on business. \"\n",
    "s4=\"eye hyperopia high hyperopic lens course objects 43 clearly distance distant headaches lenses .\" #Journal business\n",
    "\n",
    "\n",
    "query_list_verbose=[s1, s2, s3, s4]\n",
    "query_embedding = embedding_model.encode(query_list_verbose, convert_to_tensor=True)\n",
    "\n",
    "print(f\"Query: {query_list}\")\n",
    "\n",
    "# Compute dot product similarity\n",
    "start_time = timer()\n",
    "dot_scores_1 = util.dot_score(a=query_embedding, b=embeddings).T  # Shape: (n_embeddings, 3)\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# Add columns for s1, s2, s3, s4 similarity to dataframe\n",
    "for n, t in enumerate(query_list):\n",
    "    df[t]= dot_scores_1[:, n].cpu().numpy()\n",
    "\n",
    "\n",
    "# Load classifier -- not currently used. This slows down batch processing time by a lot, so is recommended for smaller datasets. \n",
    "model_path = \"trained_model.safetensors\"\n",
    "classifier = ReferenceClassifier(model_path)\n",
    "\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d344c1-2cfd-4472-8d43-9c7ae6f7194b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e0dda7-29a0-4d9c-a81b-96eb0b385d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "##But first we're going to calculate the topic scores for sentence chunk\n",
    "\n",
    "# Default value of 'a'\n",
    "a = -10\n",
    "\n",
    "# Precompute the exponentials for efficiency\n",
    "exp_values = np.exp(a * (1-df[query_list]))\n",
    "\n",
    "# Compute the denominator for softmax-like normalization\n",
    "denominator = exp_values.sum(axis=1)\n",
    "\n",
    "# Create new score columns\n",
    "\n",
    "for col in query_list:\n",
    "    score_col = f\"{col.strip()}_score\"\n",
    "    df[score_col] = exp_values[col] / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c1757a-f669-447a-a460-0c4f9e6db8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['doi']=='10.1119/1.2343490'])\n",
    "\n",
    "#df ##Score calculated by taking eahc cosine for each sentence chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2c65f2-33dd-4b7f-9d7a-cedd696fc487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabs labels form the CSV and inserts them into the dataframe. Renames the dataframe df_labels\n",
    "\n",
    "weighted_score_ql=[]\n",
    "for query in query_list:\n",
    "    weighted_score_ql.append(f\"{query}_score_weighted\")\n",
    "\n",
    "\n",
    "csv=csv.rename(columns={\"Doi\": \"doi\"})\n",
    "csv['doi']=csv['doi'].str.replace(\" \", \"\")\n",
    "csv['doi']=csv['doi'].str.replace(\"\\'\", \"\")\n",
    "csv['doi']=csv['doi'].str.replace(\"https://doi.org/\", \"\")\n",
    "\n",
    "df_labels=pd.merge(df, csv[['Category (M)', 'doi']], on='doi', how=\"left\")\n",
    "\n",
    "##At this point, the dataframe has handmade labels for the items that have received them by matching DOI. The labels are in single letter format\n",
    "##the main topic labels need to be converted to this format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1db391f-c89f-4e38-a3b3-291dcffc60b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Teaching students._score_weighted',\n",
       " 'Student focus._score_weighted',\n",
       " 'Physics content._score_weighted',\n",
       " 'Journal business._score_weighted']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_score_ql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9611cc6-be04-471f-9d05-10d1586e9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_text=df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e10804eb-2e99-497e-a7e5-c7126a52d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_labeling_recall(df, teacher_col, student_col, content_col, journal_col, main_group):\n",
    "    # Mapping of category labels to full column names\n",
    "    category_map = {\n",
    "        't': teacher_col.strip(),\n",
    "        's': student_col.strip(),\n",
    "        'c': content_col.strip(),\n",
    "        'jb': journal_col.strip()\n",
    "    }\n",
    "\n",
    "    def compare_labels(row):\n",
    "        category = row['Category (M)']\n",
    "        if pd.isna(category):\n",
    "            return np.nan\n",
    "        expected_group = category_map.get(category.strip().lower())\n",
    "        return expected_group == row[main_group]\n",
    "\n",
    "    df['Correctly labeled'] = df.apply(compare_labels, axis=1)\n",
    "    valid = df[~df['Category (M)'].isna()].copy()\n",
    "\n",
    "    print(\"Here:\")\n",
    "    print(len(valid))\n",
    "\n",
    "    total = len(valid)\n",
    "    correct = valid['Correctly labeled'].sum()\n",
    "    percent_correct = 100 * correct / total if total > 0 else 0\n",
    "\n",
    "    print(f\"1. Total number of entries with a value in 'Category (M)': {total}\")\n",
    "    print(f\"2. Percent correctly labeled (accuracy): {percent_correct:.2f}%\")\n",
    "\n",
    "    # Per-category accuracy (recall), precision, false positive rate\n",
    "    print(\"3. Detailed metrics per category:\")\n",
    "    for cat, expected_val in category_map.items():\n",
    "        # True Positives: predicted = expected = this category\n",
    "        tp = valid[(valid['Category (M)'].str.lower() == cat) & (valid[main_group] == expected_val)]\n",
    "        \n",
    "        # False Negatives: actual is this category, but predicted is not\n",
    "        fn = valid[(valid['Category (M)'].str.lower() == cat) & (valid[main_group] != expected_val)]\n",
    "\n",
    "        # False Positives: predicted is this category, but actual is not\n",
    "        fp = valid[(valid['Category (M)'].str.lower() != cat) & (valid[main_group] == expected_val)]\n",
    "\n",
    "        # True Negatives: actual and predicted are both *not* this category\n",
    "        tn = valid[(valid['Category (M)'].str.lower() != cat) & (valid[main_group] != expected_val)]\n",
    "\n",
    "        tp_count = len(tp)\n",
    "        fn_count = len(fn)\n",
    "        fp_count = len(fp)\n",
    "        tn_count = len(tn)\n",
    "\n",
    "        recall = tp_count / (tp_count + fn_count) if (tp_count + fn_count) > 0 else 0\n",
    "        precision = tp_count / (tp_count + fp_count) if (tp_count + fp_count) > 0 else 0\n",
    "        fpr = fp_count / (fp_count + tn_count) if (fp_count + tn_count) > 0 else 0\n",
    "        acc = (tp_count + tn_count) / (tp_count + tn_count + fp_count + fn_count)\n",
    "\n",
    "        print(f\"   {cat.title()}:\")\n",
    "        print(f\"      Recall (TP / TP + FN): {recall:.2f}\")\n",
    "        print(f\"      Precision (TP / TP + FP): {precision:.2f}\")\n",
    "        print(f\"      False Positive Rate (FP / FP + TN): {fpr:.2f}\")\n",
    "        print(f\"      Accuracy (TP + TN / All): {acc:.2f}\")\n",
    "\n",
    "    # Label distributions\n",
    "    print(\"4. Label distribution:\")\n",
    "    cat_counts = valid['Category (M)'].str.lower().value_counts(normalize=True)\n",
    "    main_counts = valid[main_group].value_counts(normalize=True)\n",
    "    \n",
    "    print(\"Category (M):\")\n",
    "    for k, v in cat_counts.items():\n",
    "        print(f\"     {k.title()}: {v:.2%}\")\n",
    "    print(\"Automated:\")\n",
    "    for k, v in main_counts.items():\n",
    "        print(f\"     {k[:40].strip()}: {v:.2%}\")\n",
    "\n",
    "    # Return doi and correctness\n",
    "    result = valid[['doi', 'Correctly labeled']].reset_index(drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2145b0a3-613e-4b03-b25b-488d57d0909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.ndimage as nd\n",
    "import numpy as np\n",
    "\n",
    "  \n",
    "\n",
    "def centroid_labeling_whole_text(df, K=1, whole_text=True):\n",
    "    print(len(df))\n",
    "    df_labels = df.copy()\n",
    "    print(f\"K: {K} whole_text: {whole_text}\")\n",
    "\n",
    "    # Step 1: Identify archetypal papers\n",
    "    archetypal_papers = {}\n",
    "    for label in query_list:\n",
    "        k_actual = min(K, len(df_labels))\n",
    "        top_k_dois = df_labels.sort_values(by=f\"{label}_score\", ascending=False).head(k_actual)['doi'].tolist()\n",
    "        archetypal_papers[label] = top_k_dois\n",
    "    #Hard coding in archetypal papers for Journal Business\n",
    "    #archetypal_papers['Journal business.']=['10.1119/1.1987213', '10.1119/1.15470', '10.1119/1.1975265', '10.1119/1.2339284', '10.1119/1.18630', '10.1119/1.4972266']\n",
    "    #archetypal_papers['Journal business.']=['10.1119/1.1987213', '10.1119/1.15470', '10.1119/1.1975265', '10.1119/1.2339284'] #'10.1119/1.18630', '10.1119/1.4972266']\n",
    "    #copy pasting the papers that it chose through query \n",
    "        #archetypal_papers['Journal business.']=['10.1119/1.1934911', '10.1119/1.16066', '10.1119/1.1935913', '10.1119/1.1986075', '10.1119/1.2339284']\n",
    "    \n",
    "    print(archetypal_papers['Journal business.'])\n",
    "    print(\"Here: \", archetypal_papers.keys())\n",
    "\n",
    "    \n",
    "    # Step 2: Compute centroids\n",
    "    centroids = {}\n",
    "    for label, dois in archetypal_papers.items():\n",
    "        top_embeddings = []\n",
    "\n",
    "        for doi in dois:\n",
    "            if whole_text:\n",
    "                # Use full-text embedding directly\n",
    "                paper_embedding = df_labels[df_labels['doi'] == doi]['embedding'].values\n",
    "                if len(paper_embedding) > 0:\n",
    "                    top_embeddings.append(paper_embedding[0])\n",
    "                    #print(\"Here\")\n",
    "                    #print(top_embeddings)\n",
    "                else:\n",
    "                    print(\"There's a problem\")\n",
    "            #print(top_embeddings)\n",
    "            #print(\"hereere\")\n",
    "            centroid = np.mean(np.stack(top_embeddings), axis=0)\n",
    "            centroids[label] = centroid\n",
    "\n",
    "    # Step 3: Average embeddings per paper\n",
    "    avg_embeddings = []\n",
    "\n",
    "    # Step 4: Cosine similarity to centroids\n",
    "    dot_prods={}\n",
    "    for label in query_list:\n",
    "        new_label=label+\"_Advanced Centroid dotp\"\n",
    "        sent_emb=[item for item in df_labels['embedding']]\n",
    "        #print(centroids[label])\n",
    "        topic_emb=[centroids[label]]*len(sent_emb) #Copies the topic centroid embedding to be equal in length to sent_emb. For the case of the whole paper, this should just multiply it by one\n",
    "        dot_prods[new_label]= np.diag(np.array(cosine_similarity(topic_emb, sent_emb)))  ##This uses cosine similarity instead of dot product. The vectors used here are normalized so that isn't a problem\n",
    "    for new_label in [label+\"_Advanced Centroid dotp\" for label in query_list]:\n",
    "        df_labels[new_label]=dot_prods[new_label]\n",
    "    # Step 5: Softmax scoring\n",
    "    #a = 10  # softmax scaling factor, can be adjusted if needed\n",
    "    '''\n",
    "    for item in sent_emb:  \n",
    "        print(np.linalg.norm(item))\n",
    "    for index in centroids.keys:\n",
    "        for item in centroids[inded]:   \n",
    "            print(np.linalg.norm(item))\n",
    "    '''\n",
    "    softmax_scores=[]\n",
    "    ac_dotp_labels=[label+\"_Advanced Centroid dotp\" for label in query_list]\n",
    "    for index, row in df_labels.iterrows():\n",
    "        #print(row.keys())\n",
    "        #print(type(row))\n",
    "        #print(np.exp(a* (1-row[[label+\"_Advanced Centroid dotp\" for label in query_list]].values.astype(float))))\n",
    "        #print(\"here\")\n",
    "        exp_values =np.exp(a* (1-row[ac_dotp_labels].values.astype(float)))\n",
    "        #exp_values_dict={}\n",
    "        #exp_values_dict[query_list+[\" Advanced Centroid TS\"]:exp_values]\n",
    "        denominator = exp_values.sum(axis=0)\n",
    "        #print(exp_values.sum(axis=0))\n",
    "        #print(denominator)\n",
    "        softmax_scores.append( exp_values / denominator )\n",
    "    #print(softmax_scores)\n",
    "    #df_labels[]=softmax_scores\n",
    "    softmax_scores=np.flip(nd.rotate(np.array(softmax_scores),90), axis=0)\n",
    "    print(softmax_scores[0])\n",
    "    ac_ts_labels=[label+\"_Advanced Centroid TS\" for label in query_list]\n",
    "    for n, label in enumerate(ac_ts_labels):\n",
    "        df_labels[label]=softmax_scores[n]\n",
    "    \n",
    "    # Step 7: Identify main group\n",
    "    df_labels['Main Group Advanced Centroid'] = df_labels[[f\"{label}_Advanced Centroid TS\" for label in query_list]].idxmax(axis=1)\n",
    "    df_labels['Main Group Advanced Centroid'] = df_labels['Main Group Advanced Centroid'].str.replace(\"_Advanced Centroid TS\", \"\")\n",
    "    \n",
    "    \n",
    "    return df_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ca3738-8558-4039-890e-33424aa2a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43607\n",
      "43602\n"
     ]
    }
   ],
   "source": [
    "archetypal_papers=['10.1119/1.1934911', '10.1119/1.16066', '10.1119/1.1935913', '10.1119/1.1986075', '10.1119/1.2339284']\n",
    "\n",
    "df_full_text_copy=df_full_text.copy()\n",
    "print(len(df_full_text_copy))\n",
    "df_full_text_copy=df_full_text_copy[(df_full_text_copy['doi'] != archetypal_papers[0]) & (df_full_text_copy['doi'] != archetypal_papers[1]) & (df_full_text_copy['doi'] != archetypal_papers[2]) & (df_full_text_copy['doi'] != archetypal_papers[3]) & (df_full_text_copy['doi'] != archetypal_papers[4])]\n",
    "print(len(df_full_text_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58962fd4-fc0a-47e1-89a9-aade602c3b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43602\n",
      "K: 4 whole_text: True\n",
      "['10.1119/1.1855743', '10.1119/1.4795378', '10.1119/1.15195', '10.1119/1.1484145']\n",
      "Here:  dict_keys(['Teaching students.', 'Student focus.', 'Physics content.', 'Journal business.'])\n",
      "[0.27158646 0.26518625 0.09618734 ... 0.0618028  0.04097862 0.05596693]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test=centroid_labeling_whole_text(df_full_text_copy, K=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a5fa99-4b98-41bd-ab22-b74bb8131281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_full=test.merge(df_labels[['doi', 'Category (M)']], how='left', on=\"doi\")\n",
    "\n",
    "mg1=\"Main Group Advanced Centroid\" #Advanced centroids based on full text\n",
    "mg2=\"MG Score Full Embedding\" #Non advanced centroid, labels from full text\n",
    "mg3=\"MG Score Avg Cos\" #Centroid based entirely on queries, classification based on scoring each sentence chunk and averaging those scores\n",
    "\n",
    "df1=df_full\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d58a8980-6797-4a4f-859a-2e06b6812c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.keys()\n",
    "df_full=df_full.rename(columns={\"Category (M)_x\": \"Category (M)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "082fd669-5250-4149-87e0-3089264c016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here:\n",
      "98\n",
      "1. Total number of entries with a value in 'Category (M)': 98\n",
      "2. Percent correctly labeled (accuracy): 52.04%\n",
      "3. Detailed metrics per category:\n",
      "   T:\n",
      "      Recall (TP / TP + FN): 0.30\n",
      "      Precision (TP / TP + FP): 0.41\n",
      "      False Positive Rate (FP / FP + TN): 0.13\n",
      "      Accuracy (TP + TN / All): 0.73\n",
      "   S:\n",
      "      Recall (TP / TP + FN): 1.00\n",
      "      Precision (TP / TP + FP): 0.55\n",
      "      False Positive Rate (FP / FP + TN): 0.16\n",
      "      Accuracy (TP + TN / All): 0.87\n",
      "   C:\n",
      "      Recall (TP / TP + FN): 0.64\n",
      "      Precision (TP / TP + FP): 0.53\n",
      "      False Positive Rate (FP / FP + TN): 0.29\n",
      "      Accuracy (TP + TN / All): 0.68\n",
      "   Jb:\n",
      "      Recall (TP / TP + FN): 0.27\n",
      "      Precision (TP / TP + FP): 0.58\n",
      "      False Positive Rate (FP / FP + TN): 0.07\n",
      "      Accuracy (TP + TN / All): 0.76\n",
      "4. Label distribution:\n",
      "Category (M):\n",
      "     C: 33.67%\n",
      "     Jb: 26.53%\n",
      "     T: 23.47%\n",
      "     S: 16.33%\n",
      "Automated:\n",
      "     Physics content.: 40.82%\n",
      "     Student focus.: 29.59%\n",
      "     Teaching students.: 17.35%\n",
      "     Journal business.: 12.24%\n"
     ]
    }
   ],
   "source": [
    "mg1=\"Main Group Advanced Centroid\" #Advanced centroids based on full text\n",
    "mg2=\"MG Score Full Embedding\" #Non advanced centroid, labels from full text\n",
    "mg3=\"MG Score Avg Cos\" #Not advanced, Chunked\n",
    "\n",
    "\n",
    "df1=df_full\n",
    "#mg=\"MG Score Full Embedding\"\n",
    "\n",
    "##This is Group D, the one that matters\n",
    "results = evaluate_labeling_recall(\n",
    "    df1,\n",
    "    query_list[0], #teacher_col\n",
    "    query_list[1], #student_col\n",
    "    query_list[2], #content_col\n",
    "    query_list[3], #journal_col\n",
    "    mg1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "711b064d-e2c4-4dea-8e99-83c065a277e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv=csv.rename(columns={\"Doi\": \"doi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96850b31-2edb-49da-9923-b1fcce98b121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking to see where the missing entries of Category (M) are going\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_missing_M_val(df1, df2):\n",
    "    def find_missing_elements(list1, list2):\n",
    "        set1 = set(list1)\n",
    "        set2 = set(list2)\n",
    "        \n",
    "        missing_in_list1 = list(set2 - set1)\n",
    "        missing_in_list2 = list(set1 - set2)\n",
    "    \n",
    "        return missing_in_list1, missing_in_list2\n",
    "    df1[pd.notna(df1['Category (M)']) ==True]['doi']\n",
    "    df1_values=df1[pd.notna(df1['Category (M)']) ==True]['doi']\n",
    "    df2_values=df2[pd.notna(df2['Category (M)']) ==True]['doi']\n",
    "\n",
    "    \n",
    "    \n",
    "    return find_missing_elements(df1_values, df2_values)\n",
    "find_missing_M_val(df1, csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07381b02-351e-40ad-95ba-af663cdf1f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>doi</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>char_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>sentence_chunks</th>\n",
       "      <th>num_chunks</th>\n",
       "      <th>embedding</th>\n",
       "      <th>Teaching students.</th>\n",
       "      <th>Student focus.</th>\n",
       "      <th>Physics content.</th>\n",
       "      <th>Journal business.</th>\n",
       "      <th>Teaching students._score</th>\n",
       "      <th>Student focus._score</th>\n",
       "      <th>Physics content._score</th>\n",
       "      <th>Journal business._score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12999</th>\n",
       "      <td>Nan</td>\n",
       "      <td>10.1119/1.2343490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[Nan]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Nan]]</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0063), tensor(-0.1650), tensor(0.025...</td>\n",
       "      <td>0.364036</td>\n",
       "      <td>0.399712</td>\n",
       "      <td>0.329448</td>\n",
       "      <td>0.393104</td>\n",
       "      <td>0.223531</td>\n",
       "      <td>0.319359</td>\n",
       "      <td>0.158171</td>\n",
       "      <td>0.298939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      full_text                doi  year journal  char_count  token_count  \\\n",
       "12999       Nan  10.1119/1.2343490   NaN     tpt           3         0.75   \n",
       "\n",
       "      sentences  sentences_count sentence_chunks  num_chunks  \\\n",
       "12999     [Nan]                1         [[Nan]]           1   \n",
       "\n",
       "                                               embedding  Teaching students.  \\\n",
       "12999  [tensor(0.0063), tensor(-0.1650), tensor(0.025...            0.364036   \n",
       "\n",
       "       Student focus.  Physics content.  Journal business.  \\\n",
       "12999        0.399712          0.329448           0.393104   \n",
       "\n",
       "       Teaching students._score  Student focus._score  Physics content._score  \\\n",
       "12999                  0.223531              0.319359                0.158171   \n",
       "\n",
       "       Journal business._score  \n",
       "12999                 0.298939  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text_and_embeddings[full_text_and_embeddings['doi']=='10.1119/1.2343490']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b98dca-4c9e-44c3-920d-c12869be2733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6853d506-83f6-42c1-98a2-7b7eaeb7400c",
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(df1, \"full_text_refined_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "430a8c5d-7b61-408d-8720-bf603f4be365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>doi</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>char_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>sentence_chunks</th>\n",
       "      <th>num_chunks</th>\n",
       "      <th>...</th>\n",
       "      <th>Student focus._Advanced Centroid dotp</th>\n",
       "      <th>Physics content._Advanced Centroid dotp</th>\n",
       "      <th>Journal business._Advanced Centroid dotp</th>\n",
       "      <th>Teaching students._Advanced Centroid TS</th>\n",
       "      <th>Student focus._Advanced Centroid TS</th>\n",
       "      <th>Physics content._Advanced Centroid TS</th>\n",
       "      <th>Journal business._Advanced Centroid TS</th>\n",
       "      <th>Main Group Advanced Centroid</th>\n",
       "      <th>Category (M)_y</th>\n",
       "      <th>Correctly labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Make a Mystery Circuit with a Bar Light Fixtur...</td>\n",
       "      <td>10.1119/1.2715425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>7234</td>\n",
       "      <td>1808.50</td>\n",
       "      <td>[Make a Mystery Circuit with a Bar Light Fixtu...</td>\n",
       "      <td>81</td>\n",
       "      <td>[[Make a Mystery Circuit with a Bar Light Fixt...</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567285</td>\n",
       "      <td>0.453943</td>\n",
       "      <td>0.485728</td>\n",
       "      <td>0.271586</td>\n",
       "      <td>0.412857</td>\n",
       "      <td>0.132913</td>\n",
       "      <td>0.182644</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton K...</td>\n",
       "      <td>10.1119/1.2343976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>4633</td>\n",
       "      <td>1158.25</td>\n",
       "      <td>[AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton ...</td>\n",
       "      <td>58</td>\n",
       "      <td>[[AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton...</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539128</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.479265</td>\n",
       "      <td>0.265186</td>\n",
       "      <td>0.364788</td>\n",
       "      <td>0.169552</td>\n",
       "      <td>0.200474</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modeling Electricity: Model-Based Inquiry with...</td>\n",
       "      <td>10.1119/1.4745686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>17496</td>\n",
       "      <td>4374.00</td>\n",
       "      <td>[Modeling Electricity: Model-Based Inquiry wit...</td>\n",
       "      <td>140</td>\n",
       "      <td>[[Modeling Electricity: Model-Based Inquiry wi...</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681222</td>\n",
       "      <td>0.480798</td>\n",
       "      <td>0.416193</td>\n",
       "      <td>0.096187</td>\n",
       "      <td>0.749807</td>\n",
       "      <td>0.101046</td>\n",
       "      <td>0.052959</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two Approaches to Learning Physics \\r\\n\"I look...</td>\n",
       "      <td>10.1119/1.2342910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>37322</td>\n",
       "      <td>9330.50</td>\n",
       "      <td>[Two Approaches to Learning Physics \\r\\n\"I loo...</td>\n",
       "      <td>324</td>\n",
       "      <td>[[Two Approaches to Learning Physics \\r\\n\"I lo...</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702052</td>\n",
       "      <td>0.697663</td>\n",
       "      <td>0.569715</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>0.425555</td>\n",
       "      <td>0.407280</td>\n",
       "      <td>0.113298</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\r\\nJochen Kuhn and Patrik Vogt, Column Editor...</td>\n",
       "      <td>10.1119/1.4865529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tpt</td>\n",
       "      <td>6621</td>\n",
       "      <td>1655.25</td>\n",
       "      <td>[\\r\\nJochen Kuhn and Patrik Vogt, Column Edito...</td>\n",
       "      <td>76</td>\n",
       "      <td>[[\\r\\nJochen Kuhn and Patrik Vogt, Column Edit...</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461446</td>\n",
       "      <td>0.533366</td>\n",
       "      <td>0.434795</td>\n",
       "      <td>0.385857</td>\n",
       "      <td>0.160819</td>\n",
       "      <td>0.330129</td>\n",
       "      <td>0.123195</td>\n",
       "      <td>Teaching students.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43597</th>\n",
       "      <td>Examining faculty choices while implementing t...</td>\n",
       "      <td>10.1119/perc.2023.pr.Willison</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>24881</td>\n",
       "      <td>6220.25</td>\n",
       "      <td>[Examining faculty choices while implementing ...</td>\n",
       "      <td>203</td>\n",
       "      <td>[[Examining faculty choices while implementing...</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579572</td>\n",
       "      <td>0.423246</td>\n",
       "      <td>0.323882</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.732347</td>\n",
       "      <td>0.153391</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43598</th>\n",
       "      <td>Analyzing the dimensionality of the Energy and...</td>\n",
       "      <td>10.1119/perc.2023.pr.Wu</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>24460</td>\n",
       "      <td>6115.00</td>\n",
       "      <td>[Analyzing the dimensionality of the Energy an...</td>\n",
       "      <td>227</td>\n",
       "      <td>[[Analyzing the dimensionality of the Energy a...</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687440</td>\n",
       "      <td>0.465194</td>\n",
       "      <td>0.407578</td>\n",
       "      <td>0.023987</td>\n",
       "      <td>0.834744</td>\n",
       "      <td>0.090438</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43599</th>\n",
       "      <td>Students’ use of symmetry as a tool for sensem...</td>\n",
       "      <td>10.1119/perc.2023.pr.Young</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>27598</td>\n",
       "      <td>6899.50</td>\n",
       "      <td>[Students’ use of symmetry as a tool for sense...</td>\n",
       "      <td>264</td>\n",
       "      <td>[[Students’ use of symmetry as a tool for sens...</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626704</td>\n",
       "      <td>0.428842</td>\n",
       "      <td>0.421718</td>\n",
       "      <td>0.061803</td>\n",
       "      <td>0.740479</td>\n",
       "      <td>0.102379</td>\n",
       "      <td>0.095339</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43600</th>\n",
       "      <td>Analyzing Physics Majors’ Specialization Low I...</td>\n",
       "      <td>10.1119/perc.2023.pr.Zohrabi_Alaee</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>27954</td>\n",
       "      <td>6988.50</td>\n",
       "      <td>[Analyzing Physics Majors’ Specialization Low ...</td>\n",
       "      <td>222</td>\n",
       "      <td>[[Analyzing Physics Majors’ Specialization Low...</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597576</td>\n",
       "      <td>0.474457</td>\n",
       "      <td>0.412088</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.662116</td>\n",
       "      <td>0.193302</td>\n",
       "      <td>0.103603</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43601</th>\n",
       "      <td>Analyzing AI and student responses through the...</td>\n",
       "      <td>10.1119/perc.2023.pr.Zollman</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>perc</td>\n",
       "      <td>27691</td>\n",
       "      <td>6922.75</td>\n",
       "      <td>[Analyzing AI and student responses through th...</td>\n",
       "      <td>219</td>\n",
       "      <td>[[Analyzing AI and student responses through t...</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630206</td>\n",
       "      <td>0.517070</td>\n",
       "      <td>0.358649</td>\n",
       "      <td>0.055967</td>\n",
       "      <td>0.679767</td>\n",
       "      <td>0.219288</td>\n",
       "      <td>0.044978</td>\n",
       "      <td>Student focus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43602 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  \\\n",
       "0      Make a Mystery Circuit with a Bar Light Fixtur...   \n",
       "1      AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton K...   \n",
       "2      Modeling Electricity: Model-Based Inquiry with...   \n",
       "3      Two Approaches to Learning Physics \\r\\n\"I look...   \n",
       "4      \\r\\nJochen Kuhn and Patrik Vogt, Column Editor...   \n",
       "...                                                  ...   \n",
       "43597  Examining faculty choices while implementing t...   \n",
       "43598  Analyzing the dimensionality of the Energy and...   \n",
       "43599  Students’ use of symmetry as a tool for sensem...   \n",
       "43600  Analyzing Physics Majors’ Specialization Low I...   \n",
       "43601  Analyzing AI and student responses through the...   \n",
       "\n",
       "                                      doi    year journal  char_count  \\\n",
       "0                       10.1119/1.2715425     NaN     tpt        7234   \n",
       "1                       10.1119/1.2343976     NaN     tpt        4633   \n",
       "2                       10.1119/1.4745686     NaN     tpt       17496   \n",
       "3                       10.1119/1.2342910     NaN     tpt       37322   \n",
       "4                       10.1119/1.4865529     NaN     tpt        6621   \n",
       "...                                   ...     ...     ...         ...   \n",
       "43597       10.1119/perc.2023.pr.Willison  2023.0    perc       24881   \n",
       "43598             10.1119/perc.2023.pr.Wu  2023.0    perc       24460   \n",
       "43599          10.1119/perc.2023.pr.Young  2023.0    perc       27598   \n",
       "43600  10.1119/perc.2023.pr.Zohrabi_Alaee  2023.0    perc       27954   \n",
       "43601        10.1119/perc.2023.pr.Zollman  2023.0    perc       27691   \n",
       "\n",
       "       token_count                                          sentences  \\\n",
       "0          1808.50  [Make a Mystery Circuit with a Bar Light Fixtu...   \n",
       "1          1158.25  [AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton ...   \n",
       "2          4374.00  [Modeling Electricity: Model-Based Inquiry wit...   \n",
       "3          9330.50  [Two Approaches to Learning Physics \\r\\n\"I loo...   \n",
       "4          1655.25  [\\r\\nJochen Kuhn and Patrik Vogt, Column Edito...   \n",
       "...            ...                                                ...   \n",
       "43597      6220.25  [Examining faculty choices while implementing ...   \n",
       "43598      6115.00  [Analyzing the dimensionality of the Energy an...   \n",
       "43599      6899.50  [Students’ use of symmetry as a tool for sense...   \n",
       "43600      6988.50  [Analyzing Physics Majors’ Specialization Low ...   \n",
       "43601      6922.75  [Analyzing AI and student responses through th...   \n",
       "\n",
       "       sentences_count                                    sentence_chunks  \\\n",
       "0                   81  [[Make a Mystery Circuit with a Bar Light Fixt...   \n",
       "1                   58  [[AGOLDEN OLDIE-ABLAOK BOX OIROUIT \\r\\nClifton...   \n",
       "2                  140  [[Modeling Electricity: Model-Based Inquiry wi...   \n",
       "3                  324  [[Two Approaches to Learning Physics \\r\\n\"I lo...   \n",
       "4                   76  [[\\r\\nJochen Kuhn and Patrik Vogt, Column Edit...   \n",
       "...                ...                                                ...   \n",
       "43597              203  [[Examining faculty choices while implementing...   \n",
       "43598              227  [[Analyzing the dimensionality of the Energy a...   \n",
       "43599              264  [[Students’ use of symmetry as a tool for sens...   \n",
       "43600              222  [[Analyzing Physics Majors’ Specialization Low...   \n",
       "43601              219  [[Analyzing AI and student responses through t...   \n",
       "\n",
       "       num_chunks  ... Student focus._Advanced Centroid dotp  \\\n",
       "0              17  ...                              0.567285   \n",
       "1              12  ...                              0.539128   \n",
       "2              28  ...                              0.681222   \n",
       "3              65  ...                              0.702052   \n",
       "4              16  ...                              0.461446   \n",
       "...           ...  ...                                   ...   \n",
       "43597          41  ...                              0.579572   \n",
       "43598          46  ...                              0.687440   \n",
       "43599          53  ...                              0.626704   \n",
       "43600          45  ...                              0.597576   \n",
       "43601          44  ...                              0.630206   \n",
       "\n",
       "       Physics content._Advanced Centroid dotp  \\\n",
       "0                                     0.453943   \n",
       "1                                     0.462512   \n",
       "2                                     0.480798   \n",
       "3                                     0.697663   \n",
       "4                                     0.533366   \n",
       "...                                        ...   \n",
       "43597                                 0.423246   \n",
       "43598                                 0.465194   \n",
       "43599                                 0.428842   \n",
       "43600                                 0.474457   \n",
       "43601                                 0.517070   \n",
       "\n",
       "       Journal business._Advanced Centroid dotp  \\\n",
       "0                                      0.485728   \n",
       "1                                      0.479265   \n",
       "2                                      0.416193   \n",
       "3                                      0.569715   \n",
       "4                                      0.434795   \n",
       "...                                         ...   \n",
       "43597                                  0.323882   \n",
       "43598                                  0.407578   \n",
       "43599                                  0.421718   \n",
       "43600                                  0.412088   \n",
       "43601                                  0.358649   \n",
       "\n",
       "       Teaching students._Advanced Centroid TS  \\\n",
       "0                                     0.271586   \n",
       "1                                     0.265186   \n",
       "2                                     0.096187   \n",
       "3                                     0.053867   \n",
       "4                                     0.385857   \n",
       "...                                        ...   \n",
       "43597                                 0.057473   \n",
       "43598                                 0.023987   \n",
       "43599                                 0.061803   \n",
       "43600                                 0.040979   \n",
       "43601                                 0.055967   \n",
       "\n",
       "       Student focus._Advanced Centroid TS  \\\n",
       "0                                 0.412857   \n",
       "1                                 0.364788   \n",
       "2                                 0.749807   \n",
       "3                                 0.425555   \n",
       "4                                 0.160819   \n",
       "...                                    ...   \n",
       "43597                             0.732347   \n",
       "43598                             0.834744   \n",
       "43599                             0.740479   \n",
       "43600                             0.662116   \n",
       "43601                             0.679767   \n",
       "\n",
       "       Physics content._Advanced Centroid TS  \\\n",
       "0                                   0.132913   \n",
       "1                                   0.169552   \n",
       "2                                   0.101046   \n",
       "3                                   0.407280   \n",
       "4                                   0.330129   \n",
       "...                                      ...   \n",
       "43597                               0.153391   \n",
       "43598                               0.090438   \n",
       "43599                               0.102379   \n",
       "43600                               0.193302   \n",
       "43601                               0.219288   \n",
       "\n",
       "       Journal business._Advanced Centroid TS  Main Group Advanced Centroid  \\\n",
       "0                                    0.182644                Student focus.   \n",
       "1                                    0.200474                Student focus.   \n",
       "2                                    0.052959                Student focus.   \n",
       "3                                    0.113298                Student focus.   \n",
       "4                                    0.123195            Teaching students.   \n",
       "...                                       ...                           ...   \n",
       "43597                                0.056789                Student focus.   \n",
       "43598                                0.050831                Student focus.   \n",
       "43599                                0.095339                Student focus.   \n",
       "43600                                0.103603                Student focus.   \n",
       "43601                                0.044978                Student focus.   \n",
       "\n",
       "       Category (M)_y Correctly labeled  \n",
       "0                 NaN               NaN  \n",
       "1                 NaN               NaN  \n",
       "2                 NaN               NaN  \n",
       "3                 NaN               NaN  \n",
       "4                 NaN               NaN  \n",
       "...               ...               ...  \n",
       "43597             NaN               NaN  \n",
       "43598             NaN               NaN  \n",
       "43599             NaN               NaN  \n",
       "43600             NaN               NaN  \n",
       "43601             NaN               NaN  \n",
       "\n",
       "[43602 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cd92f-e3e4-4e93-bdb9-efa75c2c79e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_4",
   "language": "python",
   "name": "lang_4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
